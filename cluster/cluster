#!/bin/bash

scripts=$(dirname $0)/scripts
source $scripts/functions.sh
command=$1
shift

# function to start|stop|delete all instances of specific component
function manage_component() {
  # $1 is component name
  # $2 is action - one of start|stop|delete
  instances=$(docker container ls -a --filter "name=$1" --format "{{ .Names }}")
  if [ "$instances" != "" ]; then
    echo "$instances" | while read instance; do
       number=$(echo $instance | tr -dc '0-9')
       $scripts/$1 $2 $number
    done
  fi
}

# function to configure local installation of components to point to the cluster
function configure_local_installation() {
  # $1 is cluster configuration - one of simple|ha
  echo "Copying configuration of $1 cluster to local installation"
  sudo cp -v $scripts/../../software/hadoop/share/conf-$1/* $HADOOP_HOME/etc/hadoop
  sudo cp -v $HADOOP_HOME/etc/hadoop/core-site.xml $HBASE_HOME/conf
  sudo cp -v $HADOOP_HOME/etc/hadoop/hdfs-site.xml $HBASE_HOME/conf
  sudo cp -v $scripts/../../software/hbase/share/conf-$1/* $HBASE_HOME/conf
  sudo sed -i "s#<value>/data</value>#<value>/tmp</value>#" \
    $HBASE_HOME/conf/hbase-site.xml
  sudo cp -v $scripts/../../software/zookeeper/share/conf-$1/* $ZOOKEEPER_HOME/conf
}

# checks for presence of cluster network and creates it if it does not exist
network=$(docker network ls | grep cluster)
if [ -z "$network" ]; then
  docker network create cluster
  echo "SETTING SPARK LOCAL IP TO BIND TO IP OF DOCKER HOST"
  docker_host_ip=$(docker network inspect cluster --format '{{(index .IPAM.Config 0).Gateway}}')
  addLineToFile "export SPARK_LOCAL_IP=$docker_host_ip" $SPARK_HOME/conf/spark-env.sh
fi

case "$command" in
  zookeeper)
    $scripts/zookeeper $@
    ;;
  namenode)
    $scripts/namenode $@
    ;;
  zkfc)
    $scripts/zkfc $@
    ;;
  datanode)
    $scripts/datanode $@
    ;;
  resourcemanager)
    $scripts/resourcemanager $@
    ;;
  nodemanager)
    $scripts/nodemanager $@
    ;;
  timelineserver)
    $scripts/timelineserver $@
    ;;
  mapredhistoryserver)
    $scripts/mapredhistoryserver $@
    ;;
  hmaster)
    $scripts/hmaster $@
    ;;
  hregionserver)
    $scripts/hregionserver $@
    ;;
  sparkhistoryserver)
    $scripts/sparkhistoryserver $@
    ;;
  create)
    case "$1" in
      ""|simple)
        configure_local_installation simple
      
        $scripts/zookeeper create 1 simple
        
        $scripts/namenode create 1 simple
                       
        $scripts/datanode create 1 simple
        
        echo "Creating /tmp/logs on HDFS to store aggregated logs"
        hadoop fs -mkdir -p /tmp/logs
        
        $scripts/resourcemanager create 1 simple
        
        $scripts/nodemanager create 1 simple
        
        $scripts/timelineserver create simple
        
        $scripts/mapredhistoryserver create simple
        
        $scripts/hmaster create 1 simple
        
        $scripts/hregionserver create 1 simple
        
        echo "Creating /spark/event-log and adding spark jars to HDFS"
        hadoop fs -mkdir -p /spark/event-log
        hadoop fs -copyFromLocal $SPARK_HOME/jars /spark
        
        $scripts/sparkhistoryserver create simple
        ;;
      ha)
        configure_local_installation ha
        
        $scripts/zookeeper create 1 ha
        $scripts/zookeeper create 2 ha
        $scripts/zookeeper create 3 ha
        
        $scripts/namenode create 1 ha
        $scripts/namenode create 2 ha
        
        $scripts/zkfc create 1 ha
        $scripts/zkfc create 2 ha
        
        $scripts/datanode create 1 ha
        $scripts/datanode create 2 ha
        
        echo "Creating /tmp/logs on HDFS to store aggregated logs"
        hadoop fs -mkdir -p /tmp/logs
        
        $scripts/resourcemanager create 1 ha
        $scripts/resourcemanager create 2 ha
        
        $scripts/nodemanager create 1 ha
        $scripts/nodemanager create 2 ha
        
        $scripts/timelineserver create ha
        
        $scripts/mapredhistoryserver create ha
        
        $scripts/hmaster create 1 ha
        $scripts/hmaster create 2 ha
        
        $scripts/hregionserver create 1 ha
        $scripts/hregionserver create 2 ha
        
        echo "Creating /spark/event-log and adding spark jars to HDFS"
        hadoop fs -mkdir -p /spark/event-log
        hadoop fs -copyFromLocal $SPARK_HOME/jars /spark
        
        $scripts/sparkhistoryserver create ha
        ;;
      *)
        echo
        echo "Usage: create [CLUSTER CONFIGURATION]"
        echo
        echo "Available cluster configurations:"
        echo
        echo "  simple"
        echo "  ha"
        echo
        echo "Default cluster configuration is simple."
        exit 1
        ;;
    esac
    ;;
  start)
    manage_component zookeeper start
    manage_component namenode start
    manage_component zkfc start
    manage_component datanode start
    manage_component resourcemanager start
    manage_component nodemanager start
    manage_component timelineserver start
    manage_component mapredhistoryserver start
    manage_component hmaster start
    manage_component hregionserver start
    manage_component sparkhistoryserver start
  ;;
  
  stop)
    manage_component sparkhistoryserver stop
    manage_component hregionserver stop
    manage_component hmaster stop
    manage_component mapredhistoryserver stop
    manage_component timelineserver stop
    manage_component nodemanager stop
    manage_component resourcemanager stop
    manage_component datanode stop
    manage_component zkfc stop
    manage_component namenode stop
    manage_component zookeeper stop
  ;;

  delete)
    manage_component sparkhistoryserver delete
    manage_component hregionserver delete
    manage_component hmaster delete
    manage_component mapredhistoryserver delete
    manage_component timelineserver delete
    manage_component nodemanager delete
    manage_component resourcemanager delete
    manage_component datanode delete
    manage_component zkfc delete
    manage_component namenode delete
    manage_component zookeeper delete
    docker network rm cluster
  ;;
  
  *)
  echo
  echo "Usage: cluster [COMMAND|COMPONENT] [OPTIONS]"
  echo 
  echo "Available components, components accept options:"
  echo "  zookeeper"
  echo "  namenode"
  echo "  zkfc"
  echo "  datanode"
  echo "  resourcemanager"
  echo "  nodemanager"
  echo "  timelineserver"
  echo "  mapredhistoryserver"
  echo "  hmaster"
  echo "  hregionserver"
  echo 
  echo "Available commands, manipulate the entire cluster, create accepts options:"
  echo "  create"
  echo "  start"
  echo "  stop"
  echo "  delete"
  echo
  exit 1
  
esac